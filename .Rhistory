library(wordcloud)
library(RColorBrewer)
api_key<- "Bfmr72dwWn2Jaxgu3TKNClPHR"
api_secret<- "L7EhbZFhruX8pvhq3EZWGMS9FBRWllCBi6wYbhxDHyN7VTwKOP"
access_token<- "307345695-Uc5xlHU4rZ2b2pAku7GH3qsiGRY028IDeWlSw56R"
access_token_secret<- "MdvDYh3rb24oC3L28NQJ1RX2x1eYMKw8GsVpE4lfkjbq5"
setup_twitter_oauth(api_key,api_secret,access_token,access_token_secret)
print("getting Trump...")
Trump = searchTwitter("Trump", n=2000, lang="en")
print("getting Clinton...")
Clinton = searchTwitter("Clinton", n=2000, lang="en")
print("got it!!")
TrumpText <- sapply(Trump, function(x) x$getText())
ClintonText = sapply(Clinton, function(x) x$getText())
catch.error = function(x)
{
# let us create a missing value for test purpose
y = NA
# Try to catch that error (NA) we just created
catch_error = tryCatch(tolower(x), error=function(e) e)
# if not an error
if (!inherits(catch_error, "error"))
y = tolower(x)
# check result if error exists, otherwise the function works fine.
return(y)
}
cleanTweets<- function(tweet){
# Clean the tweet for sentiment analysis
# remove html links, which are not required for sentiment analysis
tweet = gsub("(f|ht)(tp)(s?)(://)(.*)[.|/](.*)", " ", tweet)
# First we will remove retweet entities from  the stored tweets (text)
tweet = gsub("(RT|via)((?:\\b\\W*@\\w+)+)", " ", tweet)
# Then remove all "#Hashtag"
tweet = gsub("#\\w+", " ", tweet)
# Then remove all "@people"
tweet = gsub("@\\w+", " ", tweet)
# Then remove all the punctuation
tweet = gsub("[[:punct:]]", " ", tweet)
# Then remove numbers, we need only text for analytics
tweet = gsub("[[:digit:]]", " ", tweet)
# finally, we remove unnecessary spaces (white spaces, tabs etc)
tweet = gsub("[ \t]{2,}", " ", tweet)
tweet = gsub("^\\s+|\\s+$", "", tweet)
#tweet <- iconv(tweet, to = "utf-8", sub="")
tweet <- iconv(tweet, to = "utf-8")
# if anything else, you feel, should be removed, you can.  For example "slang words" etc using the above function and methods.
# Next we'll convert all the word in lower case.  This makes uniform pattern.
tweet = catch.error(tweet)
tweet
}
cleanTweetsAndRemoveNAs<- function(Tweets) {
TweetsCleaned = sapply(Tweets, cleanTweets)
# Remove the "NA" tweets from this tweet list
TweetsCleaned = TweetsCleaned[!is.na(TweetsCleaned)]
names(TweetsCleaned) = NULL
# Remove the repetitive tweets from this tweet list
TweetsCleaned = unique(TweetsCleaned)
TweetsCleaned
}
TrumpCleaned = cleanTweetsAndRemoveNAs(TrumpText)
ClintonCleaned = cleanTweetsAndRemoveNAs(ClintonText)
# classify emotion
TrumpEmo = classify_emotion(TrumpCleaned, algorithm="bayes", prior=1.0)
ClintonEmo = classify_emotion(ClintonCleaned, algorithm="bayes", prior=1.0)
# get emotion best fit
Temotion = TrumpEmo[,7]
Cemotion = ClintonEmo[,7]
# substitute NA's by "unknown"
Temotion[is.na(emotion)] = "unknown"
Cemotion[is.na(emotion)] = "unknown"
# classify polarity
T_pol = classify_polarity(TrumpCleaned, algorithm="bayes")
C_pol = classify_polarity(ClintonCleaned, algorithm="bayes")
# get polarity best fit
Tpolarity = T_pol[,4]
Cpolarity = C_pol[,4]
# plot distribution of emotions
ggplot(sent_df, aes(x=Temotion)) +
geom_bar(aes(y=..count.., fill=emotion)) +
scale_fill_brewer(palette="Dark2") +
labs(x="emotion categories", y="number of tweets") +
opts(title = "Sentiment Analysis of Tweets about Trump\n(classification by emotion)",
plot.title = theme_text(size=12))
ggplot(sent_df, aes(x=Cemotion)) +
geom_bar(aes(y=..count.., fill=emotion)) +
scale_fill_brewer(palette="Dark2") +
labs(x="emotion categories", y="number of tweets") +
opts(title = "Sentiment Analysis of Tweets about Clinton\n(classification by emotion)",
plot.title = theme_text(size=12))
# plot distribution of polarity
ggplot(sent_df, aes(x=Tpolarity)) +
geom_bar(aes(y=..count.., fill=polarity)) +
scale_fill_brewer(palette="RdGy") +
labs(x="polarity categories", y="number of tweets") +
opts(title = "Sentiment Analysis of Tweets about Trump\n(classification by polarity)",
install.packages("SnowballC")
source('~/Data Analysis/projects/twitter/twitter.r')
debugSource('~/Data Analysis/projects/twitter/twitter.r')
library(devtools)
#install_github("geoffjentry/twitteR").
library(twitteR)
# required pakacges
library(sentiment)
library(plyr)
library(ggplot2)
library(wordcloud)
library(RColorBrewer)
api_key<- "Bfmr72dwWn2Jaxgu3TKNClPHR"
api_secret<- "L7EhbZFhruX8pvhq3EZWGMS9FBRWllCBi6wYbhxDHyN7VTwKOP"
access_token<- "307345695-Uc5xlHU4rZ2b2pAku7GH3qsiGRY028IDeWlSw56R"
access_token_secret<- "MdvDYh3rb24oC3L28NQJ1RX2x1eYMKw8GsVpE4lfkjbq5"
setup_twitter_oauth(api_key,api_secret,access_token,access_token_secret)
print("getting Trump...")
Trump = searchTwitter("Trump", n=2000, lang="en")
library(devtools)
#install_github("geoffjentry/twitteR").
library(twitteR)
# required pakacges
library(sentiment)
library(plyr)
library(ggplot2)
library(wordcloud)
library(RColorBrewer)
api_key<- "Bfmr72dwWn2Jaxgu3TKNClPHR"
api_secret<- "L7EhbZFhruX8pvhq3EZWGMS9FBRWllCBi6wYbhxDHyN7VTwKOP"
access_token<- "307345695-Uc5xlHU4rZ2b2pAku7GH3qsiGRY028IDeWlSw56R"
access_token_secret<- "MdvDYh3rb24oC3L28NQJ1RX2x1eYMKw8GsVpE4lfkjbq5"
setup_twitter_oauth(api_key,api_secret,access_token,access_token_secret)
print("getting Trump...")
Trump = searchTwitter("Trump", n=20, lang="en")
print("getting Clinton...")
Clinton = searchTwitter("Clinton", n=20, lang="en")
print("got it!!")
TrumpText <- sapply(Trump, function(x) x$getText())
ClintonText = sapply(Clinton, function(x) x$getText())
catch.error = function(x)
{
# let us create a missing value for test purpose
y = NA
# Try to catch that error (NA) we just created
catch_error = tryCatch(tolower(x), error=function(e) e)
# if not an error
if (!inherits(catch_error, "error"))
y = tolower(x)
# check result if error exists, otherwise the function works fine.
return(y)
}
cleanTweets<- function(tweet){
# Clean the tweet for sentiment analysis
# remove html links, which are not required for sentiment analysis
tweet = gsub("(f|ht)(tp)(s?)(://)(.*)[.|/](.*)", " ", tweet)
# First we will remove retweet entities from  the stored tweets (text)
tweet = gsub("(RT|via)((?:\\b\\W*@\\w+)+)", " ", tweet)
# Then remove all "#Hashtag"
tweet = gsub("#\\w+", " ", tweet)
# Then remove all "@people"
tweet = gsub("@\\w+", " ", tweet)
# Then remove all the punctuation
tweet = gsub("[[:punct:]]", " ", tweet)
tweet <- gsub(","," ",tweet)
# Then remove numbers, we need only text for analytics
tweet = gsub("[[:digit:]]", " ", tweet)
# finally, we remove unnecessary spaces (white spaces, tabs etc)
tweet = gsub("[ \t]{2,}", " ", tweet)
tweet = gsub("^\\s+|\\s+$", "", tweet)
tweet <- iconv(tweet, to = "utf-8", sub="")
# if anything else, you feel, should be removed, you can.  For example "slang words" etc using the above function and methods.
# Next we'll convert all the word in lower case.  This makes uniform pattern.
tweet = catch.error(tweet)
tweet
}
cleanTweetsAndRemoveNAs<- function(Tweets) {
TweetsCleaned = sapply(Tweets, cleanTweets)
# Remove the "NA" tweets from this tweet list
TweetsCleaned = TweetsCleaned[!is.na(TweetsCleaned)]
names(TweetsCleaned) = NULL
# Remove the repetitive tweets from this tweet list
TweetsCleaned = unique(TweetsCleaned)
TweetsCleaned
}
TrumpCleaned = cleanTweetsAndRemoveNAs(TrumpText)
ClintonCleaned = cleanTweetsAndRemoveNAs(ClintonText)
# classify emotion
TrumpEmo = classify_emotion(TrumpCleaned, algorithm="bayes", prior=1.0)
opts(title = "Sentiment Analysis of Tweets about Trump\n(classification by emotion)",
source('~/Data Analysis/projects/twitter/twitter.r')
plot.title = theme_text(size=12))
ggplot(sent_df, aes(x=Cemotion)) +
geom_bar(aes(y=..count.., fill=emotion)) +
scale_fill_brewer(palette="Dark2") +
labs(x="emotion categories", y="number of tweets") +
opts(title = "Sentiment Analysis of Tweets about Clinton\n(classification by emotion)",
plot.title = theme_text(size=12))
# plot distribution of polarity
ggplot(sent_df, aes(x=Tpolarity)) +
geom_bar(aes(y=..count.., fill=polarity)) +
scale_fill_brewer(palette="RdGy") +
labs(x="polarity categories", y="number of tweets") +
opts(title = "Sentiment Analysis of Tweets about Trump\n(classification by polarity)",
plot.title = theme_text(size=12))
# plot distribution of polarity
ggplot(sent_df, aes(x=Cpolarity)) +
geom_bar(aes(y=..count.., fill=polarity)) +
scale_fill_brewer(palette="RdGy") +
labs(x="polarity categories", y="number of tweets") +
opts(title = "Sentiment Analysis of Tweets about Clinton\n(classification by polarity)",
plot.title = theme_text(size=12))
source('~/Data Analysis/projects/twitter/twitter.r')
source('~/Data Analysis/projects/twitter/twitter.r')
source('~/Data Analysis/projects/twitter/twitter.r')
source('~/Data Analysis/projects/twitter/twitter.r')
source('~/Data Analysis/projects/twitter/twitter.r')
debugSource('~/Data Analysis/projects/twitter/twitter.r')
library(devtools)
library(devtools)
library(devtools)
library(devtools)
library(devtools)
library(devtools)
library(devtools)
library(devtools)
#install_github("geoffjentry/twitteR").
library(twitteR)
# required pakacges
library(sentiment)
library(plyr)
library(ggplot2)
library(wordcloud)
library(RColorBrewer)
api_key<- "Bfmr72dwWn2Jaxgu3TKNClPHR"
api_secret<- "L7EhbZFhruX8pvhq3EZWGMS9FBRWllCBi6wYbhxDHyN7VTwKOP"
access_token<- "307345695-Uc5xlHU4rZ2b2pAku7GH3qsiGRY028IDeWlSw56R"
access_token_secret<- "MdvDYh3rb24oC3L28NQJ1RX2x1eYMKw8GsVpE4lfkjbq5"
setup_twitter_oauth(api_key,api_secret,access_token,access_token_secret)
print("getting Trump...")
Trump = searchTwitter("Trump", n=20, lang="en")
print("getting Clinton...")
Clinton = searchTwitter("Clinton", n=20, lang="en")
print("got it!!")
TrumpText <- sapply(Trump, function(x) x$getText())
ClintonText = sapply(Clinton, function(x) x$getText())
catch.error = function(x)
{
# let us create a missing value for test purpose
y = NA
# Try to catch that error (NA) we just created
catch_error = tryCatch(tolower(x), error=function(e) e)
# if not an error
if (!inherits(catch_error, "error"))
y = tolower(x)
# check result if error exists, otherwise the function works fine.
return(y)
}
cleanTweets<- function(tweet){
# Clean the tweet for sentiment analysis
# remove html links, which are not required for sentiment analysis
tweet = gsub("(f|ht)(tp)(s?)(://)(.*)[.|/](.*)", " ", tweet)
# First we will remove retweet entities from  the stored tweets (text)
tweet = gsub("(RT|via)((?:\\b\\W*@\\w+)+)", " ", tweet)
# Then remove all "#Hashtag"
tweet = gsub("#\\w+", " ", tweet)
# Then remove all "@people"
tweet = gsub("@\\w+", " ", tweet)
# Then remove all the punctuation
tweet = gsub("[[:punct:]]", " ", tweet)
tweet <- gsub(","," ",tweet)
# Then remove numbers, we need only text for analytics
tweet = gsub("[[:digit:]]", " ", tweet)
# finally, we remove unnecessary spaces (white spaces, tabs etc)
tweet = gsub("[ \t]{2,}", " ", tweet)
tweet = gsub("^\\s+|\\s+$", "", tweet)
tweet <- iconv(tweet, to = "utf-8", sub="")
# if anything else, you feel, should be removed, you can.  For example "slang words" etc using the above function and methods.
# Next we'll convert all the word in lower case.  This makes uniform pattern.
tweet = catch.error(tweet)
tweet
}
cleanTweetsAndRemoveNAs<- function(Tweets) {
TweetsCleaned = sapply(Tweets, cleanTweets)
# Remove the "NA" tweets from this tweet list
TweetsCleaned = TweetsCleaned[!is.na(TweetsCleaned)]
names(TweetsCleaned) = NULL
# Remove the repetitive tweets from this tweet list
TweetsCleaned = unique(TweetsCleaned)
TweetsCleaned
}
TrumpCleaned = cleanTweetsAndRemoveNAs(TrumpText)
ClintonCleaned = cleanTweetsAndRemoveNAs(ClintonText)
# classify emotion
TrumpEmo = classify_emotion(TrumpCleaned, algorithm="bayes", prior=1.0)
ClintonEmo = classify_emotion(ClintonCleaned, algorithm="bayes", prior=1.0)
# get emotion best fit
ClintonCleaned
Temotion = TrumpEmo[,7]
Cemotion = ClintonEmo[,7]
# substitute NA's by "unknown"
Temotion[is.na(Temotion)] = "unknown"
Cemotion[is.na(Cemotion)] = "unknown"
# classify polarity
T_pol = classify_polarity(TrumpCleaned, algorithm="bayes")
C_pol = classify_polarity(ClintonCleaned, algorithm="bayes")
# get polarity best fit
Tpolarity = T_pol[,4]
Cpolarity = C_pol[,4]
# create data frame
Trump_DF = data.frame(text=TrumpCleaned,
emotion=Temotion, polarity=Tpolarity, stringsAsFactors=FALSE)
Clinton_DF = data.frame(text=ClintonCleaned,
emotion=Cemotion, polarity=Cpolarity, stringsAsFactors=FALSE)
# plot distribution of emotions
ggplot(Trump_DF, aes(x=Temotion)) +
geom_bar(aes(y=..count.., fill=emotion)) +
scale_fill_brewer(palette="Dark2") +
labs(x="emotion categories", y="number of tweets",title = "Trump Emotions") +
theme(legend.position='right') + ylab('Number of Tweets') +
xlab('Polarity Categories')
ggplot(Clinton_DF, aes(x=Cemotion)) +
geom_bar(aes(y=..count.., fill=emotion)) +
scale_fill_brewer(palette="Dark2") +
labs(x="emotion categories", y="number of tweets",title = "Clinton Emotions") +
theme(legend.position='right') + ylab('Number of Tweets') +
xlab('Polarity Categories')
# plot distribution of polarity
ggplot(Trump_DF, aes(x=Tpolarity)) +
geom_bar(aes(y=..count.., fill=polarity)) +
scale_fill_brewer(palette="RdGy") +
labs(x="emotion categories", y="number of tweets",title = "Trump Polarity") +
theme(legend.position='right') + ylab('Number of Tweets') +
xlab('Polarity Categories')
# plot distribution of polarity
ggplot(Clinton_DF, aes(x=Cpolarity)) +
geom_bar(aes(y=..count.., fill=polarity)) +
scale_fill_brewer(palette="RdGy") +
labs(x="polarity categories", y="number of tweets") +
labs(x="emotion categories", y="number of tweets",title = "Clinton Polarity") +
theme(legend.position='right') + ylab('Number of Tweets') +
xlab('Polarity Categories')
debugSource('~/Data Analysis/projects/twitter/twitter.r')
debugSource('~/Data Analysis/projects/twitter/twitter.r')
debugSource('~/Data Analysis/projects/twitter/twitter.r')
debugSource('~/Data Analysis/projects/twitter/twitter.r')
debugSource('~/Data Analysis/projects/twitter/twitter.r')
library(twitteR)
# required pakacges
library(sentiment)
library(plyr)
library(ggplot2)
library(wordcloud)
library(RColorBrewer)
api_key<- "Bfmr72dwWn2Jaxgu3TKNClPHR"
api_secret<- "L7EhbZFhruX8pvhq3EZWGMS9FBRWllCBi6wYbhxDHyN7VTwKOP"
access_token<- "307345695-Uc5xlHU4rZ2b2pAku7GH3qsiGRY028IDeWlSw56R"
access_token_secret<- "MdvDYh3rb24oC3L28NQJ1RX2x1eYMKw8GsVpE4lfkjbq5"
setup_twitter_oauth(api_key,api_secret,access_token,access_token_secret)
print("getting Trump...")
Trump = searchTwitter("Trump", n=20, lang="en")
print("getting Clinton...")
Clinton = searchTwitter("Clinton", n=20, lang="en")
print("got it!!")
TrumpText <- sapply(Trump, function(x) x$getText())
ClintonText = sapply(Clinton, function(x) x$getText())
catch.error = function(x)
{
# let us create a missing value for test purpose
y = NA
# Try to catch that error (NA) we just created
catch_error = tryCatch(tolower(x), error=function(e) e)
# if not an error
if (!inherits(catch_error, "error"))
y = tolower(x)
# check result if error exists, otherwise the function works fine.
return(y)
}
cleanTweets<- function(tweet){
# Clean the tweet for sentiment analysis
# remove html links, which are not required for sentiment analysis
tweet = gsub("(f|ht)(tp)(s?)(://)(.*)[.|/](.*)", " ", tweet)
# First we will remove retweet entities from  the stored tweets (text)
tweet = gsub("(RT|via)((?:\\b\\W*@\\w+)+)", " ", tweet)
# Then remove all "#Hashtag"
tweet = gsub("#\\w+", " ", tweet)
# Then remove all "@people"
tweet = gsub("@\\w+", " ", tweet)
# Then remove all the punctuation
tweet = gsub("[[:punct:]]", " ", tweet)
tweet <- gsub(","," ",tweet)
# Then remove numbers, we need only text for analytics
tweet = gsub("[[:digit:]]", " ", tweet)
# finally, we remove unnecessary spaces (white spaces, tabs etc)
tweet = gsub("[ \t]{2,}", " ", tweet)
tweet = gsub("^\\s+|\\s+$", "", tweet)
tweet <- iconv(tweet, to = "utf-8", sub="")
# if anything else, you feel, should be removed, you can.  For example "slang words" etc using the above function and methods.
# Next we'll convert all the word in lower case.  This makes uniform pattern.
tweet = catch.error(tweet)
tweet
}
cleanTweetsAndRemoveNAs<- function(Tweets) {
TweetsCleaned = sapply(Tweets, cleanTweets)
# Remove the "NA" tweets from this tweet list
TweetsCleaned = TweetsCleaned[!is.na(TweetsCleaned)]
names(TweetsCleaned) = NULL
# Remove the repetitive tweets from this tweet list
TweetsCleaned = unique(TweetsCleaned)
TweetsCleaned
}
TrumpCleaned = cleanTweetsAndRemoveNAs(TrumpText)
ClintonCleaned = cleanTweetsAndRemoveNAs(ClintonText)
save(TrumpCleaned,file="trump.tweet")
save(ClintonCleaned,file="clinton.tweet")
# classify emotion
TrumpEmo = classify_emotion(TrumpCleaned, algorithm="bayes", prior=1.0)
ClintonEmo = classify_emotion(ClintonCleaned, algorithm="bayes", prior=1.0)
# get emotion best fit
clintonCleaned
debugSource('~/Data Analysis/projects/twitter/twitter.r')
c
c
theme(legend.position='right') + ylab('Number of Tweets') +
source('~/Data Analysis/projects/twitter/twitter.r')
source('~/Data Analysis/projects/twitter/twitter.r')
library(devtools)
#install_github("geoffjentry/twitteR").
library(twitteR)
# required pakacges
library(sentiment)
library(plyr)
library(ggplot2)
library(wordcloud)
library(RColorBrewer)
api_key<- "Bfmr72dwWn2Jaxgu3TKNClPHR"
api_secret<- "L7EhbZFhruX8pvhq3EZWGMS9FBRWllCBi6wYbhxDHyN7VTwKOP"
access_token<- "307345695-Uc5xlHU4rZ2b2pAku7GH3qsiGRY028IDeWlSw56R"
access_token_secret<- "MdvDYh3rb24oC3L28NQJ1RX2x1eYMKw8GsVpE4lfkjbq5"
setup_twitter_oauth(api_key,api_secret,access_token,access_token_secret)
print("getting Trump...")
Trump = searchTwitter("Trump", n=20, lang="en")
print("getting Clinton...")
Clinton = searchTwitter("Clinton", n=20, lang="en")
print("got it!!")
TrumpText <- sapply(Trump, function(x) x$getText())
ClintonText = sapply(Clinton, function(x) x$getText())
catch.error = function(x)
{
# let us create a missing value for test purpose
y = NA
# Try to catch that error (NA) we just created
catch_error = tryCatch(tolower(x), error=function(e) e)
# if not an error
if (!inherits(catch_error, "error"))
y = tolower(x)
# check result if error exists, otherwise the function works fine.
return(y)
}
cleanTweets<- function(tweet){
# Clean the tweet for sentiment analysis
# remove html links, which are not required for sentiment analysis
tweet = gsub("(f|ht)(tp)(s?)(://)(.*)[.|/](.*)", " ", tweet)
# First we will remove retweet entities from  the stored tweets (text)
tweet = gsub("(RT|via)((?:\\b\\W*@\\w+)+)", " ", tweet)
# Then remove all "#Hashtag"
tweet = gsub("#\\w+", " ", tweet)
# Then remove all "@people"
tweet = gsub("@\\w+", " ", tweet)
# Then remove all the punctuation
tweet = gsub("[[:punct:]]", " ", tweet)
tweet <- gsub(","," ",tweet)
# Then remove numbers, we need only text for analytics
tweet = gsub("[[:digit:]]", " ", tweet)
# finally, we remove unnecessary spaces (white spaces, tabs etc)
tweet = gsub("[ \t]{2,}", " ", tweet)
tweet = gsub("^\\s+|\\s+$", "", tweet)
tweet <- iconv(tweet, to = "utf-8", sub="")
# if anything else, you feel, should be removed, you can.  For example "slang words" etc using the above function and methods.
# Next we'll convert all the word in lower case.  This makes uniform pattern.
tweet = catch.error(tweet)
tweet
}
cleanTweetsAndRemoveNAs<- function(Tweets) {
TweetsCleaned = sapply(Tweets, cleanTweets)
# Remove the "NA" tweets from this tweet list
TweetsCleaned = TweetsCleaned[!is.na(TweetsCleaned)]
names(TweetsCleaned) = NULL
# Remove the repetitive tweets from this tweet list
TweetsCleaned = unique(TweetsCleaned)
TweetsCleaned
}
TrumpCleaned = cleanTweetsAndRemoveNAs(TrumpText)
ClintonCleaned = cleanTweetsAndRemoveNAs(ClintonText)
save(TrumpCleaned,file="trump.tweet")
save(ClintonCleaned,file="clinton.tweet")
# classify emotion
TrumpEmo = classify_emotion(TrumpCleaned, algorithm="bayes", prior=1.0)
ClintonEmo = classify_emotion(ClintonCleaned, algorithm="bayes", prior=1.0)
# get emotion best fit
source('~/Data Analysis/projects/twitter/twitter.r')
source('~/Data Analysis/projects/twitter/twitter.r')
source('~/Data Analysis/projects/twitter/twitter.r')
debugSource('~/Data Analysis/projects/twitter/twitter.r')
debugSource('~/Data Analysis/projects/twitter/twitter.r')
n
debugSource('~/Data Analysis/projects/twitter/twitter.r')
c
c
debugSource('~/Data Analysis/projects/twitter/twitter.r')
source('~/Data Analysis/projects/twitter/twitter.r')
getwd()
setwd("/home/neeraj/Data Analysis/projects/twitter")
getwd()
source('~/Data Analysis/projects/twitter/twitter.r')
View(Trump_DF)
View(Trump_DF)
